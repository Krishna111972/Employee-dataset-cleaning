ğŸ§¹ Employee Dataset Cleaning with NumPy & Pandas
ğŸ“Œ Project Overview

This project focuses on cleaning and preprocessing a messy employee dataset using NumPy and Pandas.
The dataset contained issues such as missing values, inconsistent data types, outliers, and infinite values.
The goal was to transform the raw dataset into a clean, structured, and analysis-ready format.

âš™ï¸ Data Cleaning Steps

ğŸ”¹ Handling Null & Missing Values

Identified columns with missing data
Filled or removed null values depending on the context

ğŸ”¹ Handling Outliers (ğŸ’° Salary Column)

Detected extreme outliers using IQR & Z-score methods
Removed or corrected unrealistic salary values

ğŸ”¹ Fixing Data Types

Converted columns to appropriate types (int, float, datetime, category)
Ensured dataset consistency

ğŸ”¹ Fixing Infinite Values â™¾ï¸

Replaced infinite values with NaN or meaningful defaults
Dropped affected records when necessary

ğŸ”¹ Final Touches âœ¨

Standardized text/categorical fields
Prepared dataset for analysis or ML tasks

ğŸ› ï¸ Tools & Libraries

ğŸ Python 3
ğŸ”¢ NumPy
ğŸ¼ Pandas

ğŸ“‚ Project Structure
employee-dataset-cleaning/
â”‚-- data/
â”‚   â”œâ”€â”€ employee_dataset.csv     # Original messy dataset
â”‚   â”œâ”€â”€ employee_cleaned_dataset.csv   # Cleaned dataset (final output)
â”‚
â”‚-- notebooks/
â”‚   â”œâ”€â”€ data_cleaning.py  # Jupyter notebook with step-by-step cleaning
â”‚
â”‚-- README.md                # Project documentation

ğŸš€ How to Run

Clone this repository

git clone https://github.com/Krishna111972/Employee-dataset-cleaning.git
cd employee-dataset-cleaning


Install dependencies

pip install pandas numpy


Run the Jupyter notebook or Python script to reproduce the cleaning steps

ğŸ“Š Results

âœ… No null or infinite values
âœ… Salary column cleaned of outliers
âœ… Correct data types applied
âœ… Dataset ready for analysis & visualization

ğŸ”® Future Improvements

ğŸ” Automate cleaning with reusable functions
ğŸ“ˆ Add visualizations for outlier detection
âš¡ Build a pipeline for large datasets
